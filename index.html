
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
<HEAD>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

	<STYLE type="text/css"> 

	</STYLE>
	<META name="generator" content=
	"HTML Tidy for Linux/x86 (vers 25 March 2009), see www.w3.org">
	<META name="keywords" content="tts, voice conversion, deep neural network, knndist, speaker segmentation, distance, text-to-speech, data mining">
	<META name="author" content="seyed hamidreza mohammadi">
	<TITLE>Hamid Mohammadi</TITLE>
	</HEAD>
	<BODY>
	<DIV class="container">
	<IMG alt="Portrait of Seyed Hamidreza (Hamid) Mohammadi" hspace=
	"10" vspace="5"  height="200" src="seyed_hamidreza_mohammadi_3.png" >
	<p><i><small>Chinese New Year, Feb. 2016, City of Angels</small></i>.</p>
	<H3>Hamid (<font size="-0.2">Seyed Hamidreza</font>) Mohammadi</H3>
	<!--<B>Ph.D.</B>, Center for Spoken Language Understanding (<A href=
	"http://www.ohsu.edu/xd/education/schools/school-of-medicine/departments/basic-science-departments/biomedical-engineering/center-for-spoken-language-understanding">CSLU</A>), Oregon Health &amp; Science University (<A href="http://www.ohsu.edu" style=
	"text-decoration:none;">OHSU</A>) (Formerly OGI)<BR>-->
	
    <B>Senior Software Engineer, ML</B>, <A href="https://www.youtube.com" style="text-decoration:none;">Google</A><BR>
	Email: <a href="mailto:s.hamidreza.mohammadi@gmail.com">s.hamidreza.mohammadi@gmail.com</a><BR>
	<!--ORCID: <a href="http://orcid.org/0000-0002-6892-9241">0000-0002-6892-9241</a><BR>-->
	<A href="http://scholar.google.com/citations?user=WQZzizcAAAAJ&amp;hl=en"
	style="text-decoration:none;">Google Scholar</A>.<BR>	<!--, <A href="https://github.com/shamidreza" style="text-decoration:none;">GitHub</A>.-->
	Interested in Deep Learning applied to Speech and Language Processing.<BR>
	Voice Conversion audio samples: <b><a href="demo.html">is15</a></b>, <b><a href="is18samples/">is18</a></b>, <b><a href="is19samples/">is19</a></b>.

	<!--<HR />-->
	<!--<H4>Research Interests</H4>
	<UL>

	<LI>Speech and Language Processing</LI>
	<LI>Machine Learning: Deep Learning</LI>
	</UL>

        Voice Conversion audio samples: <b><a href="demo.html">is15</a></b>, <b><a href="is18samples/">is18</a></b>, <b><a href="is19samples/">is19</a></b>.
	
	<HR />-->
	
  <!--
	<H4>Code on <img src="GitHub_Logo.png" alt="GitHub logo" width="60" height="22"></H4>
	<UL>
	<LI> 
	<a href="https://gist.github.com/shamidreza/4ec62601b4bd22480cb9">Python multi-processing</a>: A simple ipython script showing Python multi-processing abilities.
	</LI>
	<LI><a href="https://github.com/shamidreza/HTS-demo_CMU-ARCTIC-SLT-Formant">    HTS-demo_CMU-ARCTIC-SLT-Formant</a>: Synthesizing formant frequency and bandwith from text using <a href="http://hts.sp.nitech.ac.jp/">HTS 2.2</a>.</LI>

	<LI><a href="https://github.com/shamidreza/Festival-features">Festival-features</a>: A script for importing <a href="http://www.cstr.ed.ac.uk/projects/festival/">Festival</a> contextual features into Python numpy array.</LI>
	<LI><A href="https://github.com/shamidreza/pylearn2_wrapper" style=
	"text-decoration:none;">pylearn2_wrapper</A>: A simple wrapper/script for <a href="http://deeplearning.net/software/pylearn2/">pylearn2</a>, which includes Autoencoders and DNNs</LI>
	<LI> <A href="https://github.com/shamidreza/dnnmapper" style=
	"text-decoration:none;">dnnmapper</A>: Some theano scripts for feature mapping in voice conversion and more (under work) </LI>
	<LI> <A href="https://github.com/shamidreza/deepcca" style=
	"text-decoration:none;">deepcca</A>: A code for <a href="http://ttic.uchicago.edu/~klivescu/papers/andrew_icml2013.pdf">deepCCA</a> (a form of multi-view learning) written in python  (under work)  </LI>
	</UL>
	<HR /> -->
	<HR />
	<H4>Education</H4>
	<UL>
	<LI><b>Ph.D.</b> in Computer Science and Engineering, 2019, 
	<A href="http://www.ohsu.edu" style="text-decoration:none;">Oregon Health &amp; Science
	University</A>, Portland, OR.<!--<BR>
	&nbsp;&nbsp;Thesis: Working on Voice Conversion and TTS adaptation under supervision of
	<A href="http://www.cslu.ogi.edu/~kain/" style="text-decoration:none;">Dr. Alexander
	Kain</A>.--></LI>
	<LI><b>M.S.</b> in Computer Science, 2011, 
	<A href="http://www.sharif.ir/en/" style="text-decoration:none;">Sharif
	University of Technology</A>, Tehran, IRAN.<!--<BR>
	&nbsp;&nbsp;Thesis:&nbsp;"Speaker Diarization in Adverse Conditions" under supervision of <A href=
	"http://sharif.edu/~sameti/" style="text-decoration:none;">Dr. Hossein Sameti</A>.--></LI>
	<LI><b>B.S.</b> in Computer Engineering, 2009, 
	<A href="http://www.iut.ac.ir/en/" style="text-decoration:none;">Isfahan
	University of Technology</A>, Isfahan, IRAN.<!--<BR>
	&nbsp;&nbsp;Project1:&nbsp;"Isolated Persian Digit Recognition using ANN/HMM hybrid method".<BR>
	&nbsp;&nbsp;Project2:&nbsp;"Data Mining Applications in Steel Plant factories".<BR><BR>-->
	</LI>
	<!--<b><a href="coursework.html">Relevant Courses I've Taken</a></b>-->
	
	</UL>
	<!--<HR />

     
	<H4>Demo</H4>-->
	
	<!--<HR />-->
	<HR />
	<H4>Publications</H4>
	<b><a href="http://scholar.google.com/citations?user=WQZzizcAAAAJ&amp;hl=en">Full list of publications</a></b>
	<UL>

	<!--
	<LI style="text-align: justify;">M.S. Elyasi Langarani, J. van Santen, <B>S.H. Mohammadi</B>, A. Kain, Data-driven Foot-based Intonation Generator for Text-to-Speech Synthesis, Interspeech, 2015. [<A href="https://www.isca-speech.org/archive_v0/interspeech_2015/papers/i15_1596.pdf" style="text-decoration:none;">pdf</A>]
	</LI>
<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, Reducing one-to-many problem in Voice Conversion by equalizing the formant locations using dynamic frequency warping, arXiv:1510.04205, 2015. [<A href="http://arxiv.org/pdf/1510.04205v1.pdf" style="text-decoration:none;">pdf</A>] <B>(not peer-reviewed)</B></LI>
<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, H. Sameti, M.S. Elyasi Langarani,
	A. Tavanaei, KNNDIST: A Nonparametric distance measure for speaker
	segmentation, Interspeech, 2012. [<A href="https://www.isca-speech.org/archive_v0/archive_papers/interspeech_2012/i12_2282.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"http://www.isca-speech.org/archive_v0/interspeech_2012/i12_2282.html"
	style="text-decoration:none;">link</A>]
	</LI>
	<LI style="text-align: justify;">E. Morley, E. Klabbers, J. van Santen, A. Kain, <B>S.H.
	Mohammadi</B>, Synthetic F0 can Effectively Convey Speaker ID in
	Delexicalized Speech, Interspeech, 2012. [<A href="https://www.isca-speech.org/archive_v0/archive_papers/interspeech_2012/i12_0434.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"http://www.isca-speech.org/archive_v0/interspeech_2012/i12_0434.html" 
	style="text-decoration:none;">link</A>]</LI>
	<LI style="text-align: justify;">S.A Mohammadi, R. Akbari, <B>S.H. Mohammadi</B>, An efficient method based on ABC for optimal multilevel thresholding, IJST, Transactions of Electrical Engineering, 2012. [<A href="http://ijste.shirazu.ac.ir/pdf_808_997d03b0dc5e6066d28440e8267dce71.html" style="text-decoration:none;">pdf</A>]</LI>
	<LI style="text-align: justify;">S. Bahaadini, H. Sameti, F. Jabbari, <B>S.H.
	Mohammadi</B>, Glottal Pulse Shape Optimization using Simulated
	Annealing</A>, Artificial Intelligence and Signal Processing (AISP), 2012. [<A href=
	"http://ieeexplore.ieee.org/xpl/articleDetails.jsp;jsessionid=cQpyQlGShhgtS9y8txT4cX2jnmvS8SlLRHxzRdGLBD1znYfr4yKT%2158582823?arnumber=6313728&amp;contentType=Conference+Publications"
	style="text-decoration:none;">link</A>]</LI>
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, H. Sameti, A. Tavanaei, A.
	Soltani-Farani, Filter-bank Design Based on Dependencies Between Frequency
	Components and Phoneme Characteristics, EUSIPCO, 2011. [<A href="http://www.eurasip.org/Proceedings/Eusipco/Eusipco2011/papers/1569427487.pdf" style="text-decoration:none;">pdf</A>]</LI>
	<LI style="text-align: justify;">A. Tavanaei, H. Sameti, <B>S.H. Mohammadi</B>, False alarm reduction by improved filler model and
	post-processing in speech keyword spotting, MLSP, 2011. [<A href=
	"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6064588" style=
	"text-decoration:none;">link</A>]</LI>
	<LI style="text-align: justify;">S. Bahaadini, H. Sameti, <B>S.H. Mohammadi</B>, Comparative study of different excitation
	signals on Mel-generalized cepstral synthesis filters, Artificial Intelligence and
	Signal Processing (AISP), 2011. [<A href=
	"http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5960983" style=
	"text-decoration:none; text-decoration:none;">link</A>]</LI>
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, J. van Santen, Making Conversational Vowels More Clear, Interspeech, 2012.  [<A href="https://www.isca-speech.org/archive_v0/archive_papers/interspeech_2012/i12_0643.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"http://www.isca-speech.org/archive_v0/interspeech_2012/i12_0643.html" style=
	"text-decoration:none;">link</A>]</LI>
	-->
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, T. Kim, One-shot voice conversion with disentangled representations by leveraging phonetic posteriograms, Interspeech, 2019. [<A href="https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/1798.pdf" style="text-decoration:none;">pdf</A>, <A href="https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/1798.html" style="text-decoration:none;">link</A>, <A href="is19samples/" style="text-decoration:none;">samples</A>, <A href="papers/Interspeech_2019_poster.pdf" style="text-decoration:none;">poster</A>]</LI>
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, Speech Representation Learning for Voice Conversion: A Dissertation, Oregon Health & Science University, 2019. [<A href="https://digitalcollections.ohsu.edu/downloads/vt150j94w?locale=en" style="text-decoration:none;">pdf</A>, <A href="https://digitalcollections.ohsu.edu/concern/etds/z316q221w?locale=en" style="text-decoration:none;">link</A>]</LI>
		<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, T. Kim, Investigation of using disentangled and interpretable representations for one-shot cross-lingual voice conversion, Interspeech, 2018. [<A href="https://isca-speech.org/archive_v0/Interspeech_2018/pdfs/2525.pdf" style="text-decoration:none;">pdf</A>, <A href="https://oben.me/one-shot-voice-conversion-using-variational-autoencoders/" style="text-decoration:none;">blog post</A>, <A href="is18samples/" style="text-decoration:none;">samples</A>, <A href="papers/is18_poster.pdf" style="text-decoration:none;">poster</A>]</LI>
        <LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, Siamese Autoencoders for Speech Style Extraction and Switching Applied to Voice Identification and Conversion, Interspeech, 2017. [<A href="http://www.isca-speech.org/archive_v0/Interspeech_2017/pdfs/1434.PDF" style="text-decoration:none;">pdf</A>, <A href="http://www.isca-speech.org/archive_v0/Interspeech_2017/abstracts/1434.html" style="text-decoration:none;">link</A>]</LI>
        <LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, An overview of voice conversion systems, Speech Communication, 2017. [<A href="papers/mohammadi_2017_overview.pdf" style="text-decoration:none;">pdf</A>, <A href="http://www.sciencedirect.com/science/article/pii/S0167639315300698" style="text-decoration:none;">link</A>]</LI>
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, A Voice Conversion Mapping Function based on a Stacked Joint-Autoencoder, Interspeech, 2016. [<A href="https://www.isca-speech.org/archive_v0/Interspeech_2016/pdfs/1437.PDF" style="text-decoration:none;">pdf</A>, <A href="https://www.isca-speech.org/archive_v0/Interspeech_2016/abstracts/1437.html" style="text-decoration:none;">link</A>]</LI>


	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, Semi-supervised Training of a Voice Conversion Mapping Function using Joint-Autoencoder, Interspeech, 2015. [<A href="https://www.isca-speech.org/archive_v0/interspeech_2015/papers/i15_0284.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"papers/IS15_poster.pdf" style=
	"text-decoration:none;">poster</A>]
	</LI>

	
    
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, Voice Conversion Using Deep Neural Networks With Speaker-Independent Pre-Training, SLT, 2014. [<A href=
	"papers/slt14_paper.pdf" style=
	"text-decoration:none;">pdf</A>, <A href=
	"papers/slt14_poster.pdf" style=
	"text-decoration:none;">poster</A>, <A href=
	"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=7078543" style=
	"text-decoration:none;">link</A>] </LI> 

	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, Transmutative Voice Conversion, ICASSP, 2013. [<A href=
	"http://cslu.ohsu.edu/~kain/pub/Mohammadi2013-ICASSP-Transmutative.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"papers/ICASSP13_presentation.pdf" style=
	"text-decoration:none;">slides</A>, <A href=
	"http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6639003&url=http%3A%2F%2Fieeexplore.ieee.org%2Fiel7%2F6619549%2F6637585%2F06639003.pdf%3Farnumber%3D6639003" style=
	"text-decoration:none;">link</A>]</LI>
	
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, A. Kain, J. van Santen, Making Conversational Vowels More Clear, Interspeech, 2012.  [<A href="https://www.isca-speech.org/archive_v0/archive_papers/interspeech_2012/i12_0643.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"http://www.isca-speech.org/archive_v0/interspeech_2012/i12_0643.html" style=
	"text-decoration:none;">link</A>]</LI>
		
	<LI style="text-align: justify;"><B>S.H. Mohammadi</B>, H. Sameti, et al, KNNDIST: A Nonparametric distance measure for speaker
	segmentation, Interspeech, 2012. [<A href="https://www.isca-speech.org/archive_v0/archive_papers/interspeech_2012/i12_2282.pdf" style="text-decoration:none;">pdf</A>, <A href=
	"http://www.isca-speech.org/archive_v0/interspeech_2012/i12_2282.html"
	style="text-decoration:none;">link</A>]
	</LI>
	
	</UL>
	

	<!--<HR />-->
	<HR />
	<H4>Talks and Presentations</H4>
	<b><a href="talks.html">Full list of talks</a></b>
	<UL>
        <LI> Deep Neural Networks in Automatic Speech Recognition, <a href="http://www.seas.ucla.edu/spapl">Guest Co-Lecturer</a>, Advanced Topics in Speech Processing Course at UCLA Spring 2019, 2019-04-11.</LI>
	<LI> Speech Representation Learning for Voice Conversion, <a href="https://digitalcollections.ohsu.edu/concern/etds/z316q221w?locale=en">Thesis Defense</a>, 2019-02-15. [<a href="https://digitalcollections.ohsu.edu/downloads/vt150j94w?locale=en">pdf</a>]</LI>
	<LI> Deep Learning; A Hands-on Introduction, <a href="http://www.seas.ucla.edu/spapl">Guest Lecturer</a>, Advanced Topics in Speech Processing Course at UCLA Spring 2018, 2018-04-23. [<a href="talk_2018_04_23_introtodeeplearning_ucla.pdf">slides</a>]</LI> 
	<LI> Introduction to Deep Learning, <a href="http://www.seas.ucla.edu/spapl">Guest Lecturer</a>, Advanced Topics in Speech Processing Course at UCLA Spring 2017, 2017-04-18. </LI>
	<LI> Capturing and Synthesizing Human Voice, <a href="http://www.seas.ucla.edu/spapl">Guest Lecturer</a>, Speech Processing Course at UCLA Spring 2016, 2016-04-13. </LI>
	<!--<LI> Deep Architectures for Voice Conversion and Speech Synthesis, <a href="http://cslu.ohsu.edu/seminar/">Thesis Proposal</a>, 2016-03-09. </LI>-->
	<LI> Recent advances in Speech Generation using Deep Learning Techniques, <a href="https://www.ohsu.edu/xd/research/centers-institutes/center-for-spoken-language-understanding/">Guest Lecturer</a>, Deep Learning Course at OHSU Fall 2015, 2015-09-28. [<a href="papers/DNN_TTS.pdf">slides</a>]
	</LI>
	<LI>
	Deep Learning, <a href="https://www.ohsu.edu/xd/research/centers-institutes/center-for-spoken-language-understanding/">Guest Lecturer</a>, Machine Learning Course at OHSU Spring 2015, 2015-06-01. [<a href="papers/ML_deeplearning.pdf">slides</a>]
	</LI>
	</UL>

    

	<!--<HR />-->
	<HR />
	<H4>Reviewer</H4>
	<UL>
	<LI>IEEE/ACM Transactions on Audio, Speech and Language Processing Journal (TASLP)</LI>
	<LI>Speech Communication (SPECOM)</LI>
        <LI>Computer Speech and Language (CSL)</LI>
        <LI>Journal of AI Research (JAIR)</LI> 
	<LI>IEEE Transactions on Neural Networks and Learning Systems</LI>
	<LI>Neural Networks</LI>
	<LI>IEEE-TCDS, JASA-EL, Interspeech, ICASSP, APSIPA-TSIP, ICCT, AISP</LI>
	

	</UL>
	
	<!--
	<HR />
	<H4>Skills</H4>

	<UL>
        <LI>
        Programming: Python, C/C++
        </LI>
        <LI>
        Toolkits, ML: Theano, TensorFlow, Keras, PyTorch, scikit-learn
        </LI>
        <LI>
        Toolkits, Speech: Merlin, Festival, HTS, HTK, SPTK, WORLD
        </LI>
    </UL>-->
    <!-- Programming: Python, C/C++, C#, ...<br/>
    Toolkits, ML: Theano, TensorFlow, Keras, PyTorch, scikit-learn<br/>
    Toolkits, Speech: Merlin, Festival, HTS, HTK, SPTK, WORLD -->
    <!--<HR />-->
    <HR />
	<H4>Miscellaneous</H4>
	<UL>
        <LI>
        How I speed up Ubuntu 16.04 LTS that is intalled on VirtualBox on MacOS. <a href="https://gist.github.com/shamidreza/be25bde686f98c8699ad9b0a522df4cc">link</a>
        </LI>
        <LI> 
	A simple ipython script showing Python multi-processing abilities. <a href="https://gist.github.com/shamidreza/4ec62601b4bd22480cb9">link</a>.
	</LI>
	<LI><a href="https://github.com/shamidreza/HTS-demo_CMU-ARCTIC-SLT-Formant">    HTS-demo_CMU-ARCTIC-SLT-Formant</a>: Synthesizing formant frequency and bandwith from text using <a href="http://hts.sp.nitech.ac.jp/">HTS 2.2</a>.</LI>
	<LI>
	How I Install Google Play Store Apps on my Amazon Fire 5th gen. <a href="https://gist.github.com/shamidreza/52bb5a4171cf1ff053eb997a32674549">link</a>
	</LI>
	<!--<LI>
	M.S. Elyasi Langarani, J. van Santen "Foot-based Intonation for Text-to-Speech Synthesis using Neural Networks", Speech-Prosody(SP) 2016. <a href="http://cslu.ohsu.edu/~elyasila/Elyasi_SP16.pdf">pdf</a>
	</LI>-->
	</UL>

	<i>Last updated: 2022-04-11 (<a href="http://en.wikipedia.org/wiki/ISO_8601" target="_blank">ISO 8601</a>)</i>
	<br/>
	<br/>
<!--<a href="https://clustrmaps.com/site/1a5f7" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=td5aYpdAejR0JV1FPJdt9qXr5xa4Yfe9axcPWN2tcac&cl=ffffff"></a>-->


	</BODY>
	</HTML>
